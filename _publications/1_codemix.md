---
title: 'From Human Judgements to Predictive Models: Unravelling Acceptability in Code-Mixed Sentences'
collection: publications
permalink: /publication/1_codemix
excerpt: 'We create the largest dataset containing human acceptability judgements for English-Hindi (en-hi) code-mixed text and demonstrate how MLLMs fine-tuned on larger data outperform ChatGPT.'
date: 2024-10-14
venue: 'ACM Transactions on Asian and Low-Resource Language Information Processing'
paperurl: 'https://arxiv.org/abs/2405.05572'
---
We construct Cline - a dataset containing human acceptability judgements for English-Hindi (en-hi) code-mixed text - the largest of its kind with 16,642 sentences. Our analysis establishes that popular code-mixing metrics such as CMI, Number of Switch Points, Burstines, which are used to filter/curate/compare code-mixed corpora have low correlation with human acceptability judgements, underlining the necessity of our dataset. Comparison with ChatGPT's zero and fewshot capabilities shows that MLLMs fine-tuned on larger data outperform ChatGPT, providing scope for improvement in code-mixed tasks. Zero-shot transfer from English-Hindi to English-Telugu acceptability judgments using our model checkpoints proves superior to random baselines, suggesting application to other code-mixed language pairs.
