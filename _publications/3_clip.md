---
title: 'Emergence of Text Semantics in CLIP Image Encoders'
collection: publications
permalink: /publication/3_clip
excerpt: "We show evidence suggesting that the image representations of CLIP have a subspace for textual semantics that abstracts away fonts. Furthermore, we show that the rendered text representations from the image encoder only slightly lag behind the text representations with respect to preserving semantic relationships."
date: 2024-11-05
venue: 'UniReps @ 38th Conference on Neural Information Processing Systems'
paperurl: 'https://openreview.net/pdf?id=eEtFRl7ksZ'
---
Certain self-supervised approaches to train image encoders, like CLIP, align images with their text captions. However, these approaches do not have an a priori incentive to learn to associate text inside the image with the semantics of the text. Our work studies the semantics of text rendered in images. We show evidence suggesting that the image representations of CLIP have a subspace for textual semantics that abstracts away fonts. Furthermore, we show that the rendered text representations from the image encoder only slightly lag behind the text representations with respect to preserving semantic relationships.

 
